
@misc{noauthor_what_nodate,
	title = {What is a {Data} {Architecture}? {Modern} {Data} {Architectures} {Explained} - {YouTube}},
	url = {https://www.youtube.com/watch?v=64TpELBlqAk},
	urldate = {2024-12-12},
}

@article{osullivan_applying_2014,
	title = {Applying data models to big data architectures},
	volume = {58},
	issn = {0018-8646},
	url = {https://ieeexplore.ieee.org/abstract/document/6964875},
	doi = {10.1147/JRD.2014.2352474},
	abstract = {A key message from the early adopters of big data is that technologies such as Hadoop®, NoSQL (Not Only Structured Query Language) databases, and stream computing should not be seen as completely separate technologies but are more valuable when deployed in conjunction with more traditional data management components. There is an urgent need for an overall blueprint for treating both the new and traditional data management components in a holistic and integrated manner. A models-driven approach ensures consistency across this data management landscape in terms of management, governance, and efficiency. This paper focuses on the data modeling considerations relating the big data deployment using the examples of transaction data and mixed unstructured data to ensure that data components are evolved to maximize business value and development efficiencies.},
	number = {5/6},
	urldate = {2024-12-12},
	journal = {IBM Journal of Research and Development},
	author = {O'Sullivan, P. and Thompson, G. and Clifford, A.},
	month = sep,
	year = {2014},
	note = {Conference Name: IBM Journal of Research and Development},
	keywords = {Big data, Business, Data models, Database management, Transaction processsing},
	pages = {18:1--18:11},
}

@inproceedings{sibley_data_1977,
	address = {New York, NY, USA},
	series = {{AFIPS} '77},
	title = {Data architecture and data model considerations},
	isbn = {978-1-4503-7914-4},
	url = {https://dl.acm.org/doi/10.1145/1499402.1499422},
	doi = {10.1145/1499402.1499422},
	abstract = {The Data Base Management System is now a well established part of information systems technology, but the many architectures and their plethora of data models are confusing to both the practitioner and researcher. In the past, attempts have been made to compare and contrast some of these systems, but the greatest difficulty arises in seeking a common basis. This paper attempts to show how a generalized data system (GDS), represented by two different models, could form such a basis; it then proposes that data policy definitions can restrict the GDS to a specialized model, such as a relational or DBTG-like model. Finally, it proposes that this concept forms a better basis for data structure design of specific system applications.},
	urldate = {2024-12-12},
	booktitle = {Proceedings of the {June} 13-16, 1977, national computer conference},
	publisher = {Association for Computing Machinery},
	author = {Sibley, Edgar H. and Kerschberg, Larry},
	year = {1977},
	pages = {85--96},
}

@misc{narayanan_critical_2012,
	title = {A {Critical} {Look} at {Decentralized} {Personal} {Data} {Architectures}},
	url = {http://arxiv.org/abs/1202.4503},
	doi = {10.48550/arXiv.1202.4503},
	abstract = {While the Internet was conceived as a decentralized network, the most widely used web applications today tend toward centralization. Control increasingly rests with centralized service providers who, as a consequence, have also amassed unprecedented amounts of data about the behaviors and personalities of individuals. Developers, regulators, and consumer advocates have looked to alternative decentralized architectures as the natural response to threats posed by these centralized services. The result has been a great variety of solutions that include personal data stores (PDS), infomediaries, Vendor Relationship Management (VRM) systems, and federated and distributed social networks. And yet, for all these efforts, decentralized personal data architectures have seen little adoption. This position paper attempts to account for these failures, challenging the accepted wisdom in the web community on the feasibility and desirability of these approaches. We start with a historical discussion of the development of various categories of decentralized personal data architectures. Then we survey the main ideas to illustrate the common themes among these efforts. We tease apart the design characteristics of these systems from the social values that they (are intended to) promote. We use this understanding to point out numerous drawbacks of the decentralization paradigm, some inherent and others incidental. We end with recommendations for designers of these systems for working towards goals that are achievable, but perhaps more limited in scope and ambition.},
	urldate = {2024-12-12},
	publisher = {arXiv},
	author = {Narayanan, Arvind and Toubiana, Vincent and Barocas, Solon and Nissenbaum, Helen and Boneh, Dan},
	month = feb,
	year = {2012},
	note = {arXiv:1202.4503 [cs]},
	keywords = {Computer Science - Computers and Society},
}

@article{machado_data_2022,
	series = {International {Conference} on {ENTERprise} {Information} {Systems} / {ProjMAN} - {International} {Conference} on {Project} {MANagement} / {HCist} - {International} {Conference} on {Health} and {Social} {Care} {Information} {Systems} and {Technologies} 2021},
	title = {Data {Mesh}: {Concepts} and {Principles} of a {Paradigm} {Shift} in {Data} {Architectures}},
	volume = {196},
	issn = {1877-0509},
	shorttitle = {Data {Mesh}},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050921022365},
	doi = {10.1016/j.procs.2021.12.013},
	abstract = {Inherent to the growing use of the most varied forms of software (e.g., social applications), there is the creation and storage of data that, due to its characteristics (volume, variety, and velocity), make the concept of Big Data emerge. Big Data Warehouses and Data Lakes are concepts already well established and implemented by several organizations, to serve their decision-making needs. After analyzing the various problems demonstrated by those monolithic architectures, it is possible to conclude about the need for a paradigm shift that will make organizations truly data-oriented. In this new paradigm, data is seen as the main concern of the organization, and the pipelining tools and the Data Lake itself are seen as a secondary concern. Thus, the Data Mesh consists in the implementation of an architecture where data is intentionally distributed among several Mesh nodes, in such a way that there is no chaos or data silos, since there are centralized governance strategies and the guarantee that the core principles are shared throughout the Mesh nodes. This paper presents the motivation for the appearance of the Data Mesh paradigm, its features, and approaches for its implementation.},
	urldate = {2024-12-12},
	journal = {Procedia Computer Science},
	author = {Machado, Inês Araújo and Costa, Carlos and Santos, Maribel Yasmina},
	month = jan,
	year = {2022},
	keywords = {Big Data, Data Architectures, Data Lake, Data Mesh},
	pages = {263--271},
}

@article{manogaran_survey_2017,
	title = {A survey of big data architectures and machine learning algorithms in healthcare},
	volume = {25},
	issn = {1752-6418},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJBET.2017.087722},
	doi = {10.1504/IJBET.2017.087722},
	abstract = {Big Data has gained much attention from researchers in healthcare, bioinformatics, and information sciences. As a result, data production at this stage will be 44 times greater than that in 2009. Hence, the volume, velocity, and variety of data rapidly increase. Hence, it is difficult to store, process and visualise this huge data using traditional technologies. Many organisations such as Twitter, LinkedIn, and Facebook are used big data for different use cases in the social networking domain. Also, implementations of such architectures of the use cases have been published worldwide. However, a conceptual architecture for specific big data application has been limited. The intention of this paper is application-oriented architecture for big data systems, which is based on a study of published big data architectures for specific use cases. This paper also provides an overview of the state-of-the-art machine learning algorithms for processing big data in healthcare and other applications.},
	number = {2-4},
	urldate = {2024-12-12},
	journal = {International Journal of Biomedical Engineering and Technology},
	author = {Manogaran, Gunasekaran and Lopez, Daphne},
	month = jan,
	year = {2017},
	note = {Publisher: Inderscience Publishers},
	keywords = {big data, big data applications, big data architectures, big data opportunities and challenges, healthcare, machine learning algorithms},
	pages = {182--211},
}

@book{kozielski_beyond_2015,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Beyond {Databases}, {Architectures} and {Structures}: 11th {International} {Conference}, {BDAS} 2015, {Ustroń}, {Poland}, {May} 26-29, 2015, {Proceedings}},
	volume = {521},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-319-18421-0 978-3-319-18422-7},
	shorttitle = {Beyond {Databases}, {Architectures} and {Structures}},
	url = {https://link.springer.com/10.1007/978-3-319-18422-7},
	language = {en},
	urldate = {2024-12-12},
	publisher = {Springer International Publishing},
	editor = {Kozielski, Stanisław and Mrozek, Dariusz and Kasprowski, Paweł and Małysiak-Mrozek, Bożena and Kostrzewa, Daniel},
	year = {2015},
	doi = {10.1007/978-3-319-18422-7},
	keywords = {Artificial intelligence, Data acquisition, Data analysis, Data management systems, Data mining, Data processing, Data storage, Data structures, Data warehouses, Database design and models, Database performance, Database query processing, Database systems, ETL, Information integration, Information systems, Machine learning, NoSQL databases, Ontologies, Semantic web},
}

@book{inmon_data_2014,
	title = {Data {Architecture}: {A} {Primer} for the {Data} {Scientist}: {Big} {Data}, {Data} {Warehouse} and {Data} {Vault}},
	isbn = {978-0-12-802091-3},
	shorttitle = {Data {Architecture}},
	abstract = {Today, the world is trying to create and educate data scientists because of the phenomenon of Big Data. And everyone is looking deeply into this technology. But no one is looking at the larger architectural picture of how Big Data needs to fit within the existing systems (data warehousing systems). Taking a look at the larger picture into which Big Data fits gives the data scientist the necessary context for how pieces of the puzzle should fit together. Most references on Big Data look at only one tiny part of a much larger whole. Until data gathered can be put into an existing framework or architecture it can't be used to its full potential. Data Architecture a Primer for the Data Scientist addresses the larger architectural picture of how Big Data fits with the existing information infrastructure, an essential topic for the data scientist. Drawing upon years of practical experience and using numerous examples and an easy to understand framework. W.H. Inmon, and Daniel Linstedt define the importance of data architecture and how it can be used effectively to harness big data within existing systems. You'll be able to: - Turn textual information into a form that can be analyzed by standard tools. - Make the connection between analytics and Big Data - Understand how Big Data fits within an existing systems environment - Conduct analytics on repetitive and non-repetitive data - Discusses the value in Big Data that is often overlooked, non-repetitive data, and why there is significant business value in using it - Shows how to turn textual information into a form that can be analyzed by standard tools - Explains how Big Data fits within an existing systems environment - Presents new opportunities that are afforded by the advent of Big Data - Demystifies the murky waters of repetitive and non-repetitive data in Big Data},
	language = {en},
	publisher = {Morgan Kaufmann},
	author = {Inmon, W. H. and Linstedt, Daniel},
	month = nov,
	year = {2014},
	note = {Google-Books-ID: \_e59BAAAQBAJ},
	keywords = {Computers / Business \& Productivity Software / Business Intelligence, Computers / Database Administration \& Management},
}

@book{lipp_modern_2023,
	address = {Birmingham, UK},
	edition = {1st edition.},
	title = {{MODERN} {DATA} {ARCHITECTURES} {WITH} {PYTHON}: a practical guide to building and deploying data pipelines, data warehouses, and data lakes with {Python}},
	isbn = {978-1-80107-641-8 978-1-80107-049-2},
	shorttitle = {{MODERN} {DATA} {ARCHITECTURES} {WITH} {PYTHON}},
	url = {https://learning.oreilly.com/library/view/-/9781801070492/?ar},
	language = {eng},
	urldate = {2024-12-12},
	publisher = {Packt Publishing Ltd.},
	author = {Lipp, Brian},
	year = {2023},
}

@inproceedings{bakshi_considerations_2012,
	title = {Considerations for big data: {Architecture} and approach},
	shorttitle = {Considerations for big data},
	url = {https://ieeexplore.ieee.org/abstract/document/6187357},
	doi = {10.1109/AERO.2012.6187357},
	abstract = {The amount of data in our industry and the world is exploding. Data is being collected and stored at unprecedented rates. The challenge is not only to store and manage the vast volume of data (“big data”), but also to analyze and extract meaningful value from it. There are several approaches to collecting, storing, processing, and analyzing big data. The main focus of the paper is on unstructured data analysis. Unstructured data refers to information that either does not have a pre-defined data model or does not fit well into relational tables. Unstructured data is the fastest growing type of data, some example could be imagery, sensors, telemetry, video, documents, log files, and email data files. There are several techniques to address this problem space of unstructured analytics. The techniques share a common characteristics of scale-out, elasticity and high availability. MapReduce, in conjunction with the Hadoop Distributed File System (HDFS) and HBase database, as part of the Apache Hadoop project is a modern approach to analyze unstructured data. Hadoop clusters are an effective means of processing massive volumes of data, and can be improved with the right architectural approach.},
	urldate = {2024-12-12},
	booktitle = {2012 {IEEE} {Aerospace} {Conference}},
	author = {Bakshi, Kapil},
	month = mar,
	year = {2012},
	note = {ISSN: 1095-323X},
	keywords = {Availability, Benchmark testing, Computer architecture, Distributed databases, File systems, Relational databases},
	pages = {1--7},
}

@book{ryzko_modern_2020,
	title = {Modern {Big} {Data} {Architectures}: {A} {Multi}-{Agent} {Systems} {Perspective}},
	isbn = {978-1-119-59784-1},
	shorttitle = {Modern {Big} {Data} {Architectures}},
	abstract = {Provides an up-to-date analysis of big data and multi-agent systems The term Big Data refers to the cases, where data sets are too large or too complex for traditional data-processing software. With the spread of new concepts such as Edge Computing or the Internet of Things, production, processing and consumption of this data becomes more and more distributed. As a result, applications increasingly require multiple agents that can work together. A multi-agent system (MAS) is a self-organized computer system that comprises multiple intelligent agents interacting to solve problems that are beyond the capacities of individual agents. Modern Big Data Architectures examines modern concepts and architecture for Big Data processing and analytics. This unique, up-to-date volume provides joint analysis of big data and multi-agent systems, with emphasis on distributed, intelligent processing of very large data sets. Each chapter contains practical examples and detailed solutions suitable for a wide variety of applications. The author, an internationally-recognized expert in Big Data and distributed Artificial Intelligence, demonstrates how base concepts such as agent, actor, and micro-service have reached a point of convergence—enabling next generation systems to be built by incorporating the best aspects of the field. This book:  Illustrates how data sets are produced and how they can be utilized in various areas of industry and science Explains how to apply common computational models and state-of-the-art architectures to process Big Data tasks Discusses current and emerging Big Data applications of Artificial Intelligence  Modern Big Data Architectures: A Multi-Agent Systems Perspective is a timely and important resource for data science professionals and students involved in Big Data analytics, and machine and artificial learning.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Ryzko, Dominik},
	month = mar,
	year = {2020},
	note = {Google-Books-ID: PL7TDwAAQBAJ},
	keywords = {Computers / Computer Science, Computers / Data Science / Data Analytics, Computers / Database Administration \& Management, Computers / Information Technology, Computers / Machine Theory},
}

@inproceedings{priebe_finding_2021,
	title = {Finding {Your} {Way} {Through} the {Jungle} of {Big} {Data} {Architectures}},
	url = {https://ieeexplore.ieee.org/abstract/document/9671862},
	doi = {10.1109/BigData52589.2021.9671862},
	abstract = {This paper presents a systematic review of common analytical data architectures based on DAMA-DMBOK and ArchiMate. The paper is work in progress and provides a first view on Gartner’s Logical Data Warehouse paradigm, Data Fabric and Dehghani’s Data Mesh proposal as well as their interdependencies. It furthermore sketches the way forward how this work can be extended by covering more architecture paradigms (incl. classic Data Warehouse, Data Vault, Data Lake, Lambda and Kappa architectures) and introducing a template with among others "context", "problem" and "solution" descriptions, leading ultimately to a pattern system providing guidance for choosing the right architecture paradigm for the right situation},
	urldate = {2024-12-12},
	booktitle = {2021 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Priebe, Torsten and Neumaier, Sebastian and Markus, Stefan},
	month = dec,
	year = {2021},
	keywords = {Big Data applications, Computer architecture, Conferences, Data Architecture, Data Fabric, Data Lake, Data Mesh, Data warehouses, Fabrics, Logical Data Warehouse, Software design, Systematics},
	pages = {5994--5996},
}

@inproceedings{guzel_kalayci_ontop-temporal_2018,
	address = {New York, NY, USA},
	series = {{CIKM} '18},
	title = {Ontop-temporal: {A} {Tool} for {Ontology}-based {Query} {Answering} over {Temporal} {Data}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {Ontop-temporal},
	url = {https://doi.org/10.1145/3269206.3269230},
	doi = {10.1145/3269206.3269230},
	abstract = {We present Ontop-temporal, an extension of the ontology-based data access system Ontop for query answering with temporal data and ontologies. Ontop is a system to answer SPARQL queries over various data stores, using standard R2RML mappings and an OWL2QL domain ontology to produce high-level conceptual views over the raw data. The Ontop-temporal extension is designed to handle timestamped log data, by additionally using (i) mappings supporting validity time specification, and (ii) rules based on metric temporal logic to define temporalised concepts. In this demo we present how Ontop-temporal can be used to facilitate the access to the MIMIC-III critical care unit dataset containing log data on hospital admissions, procedures, and diagnoses. We use the ICD9CM diagnoses ontology and temporal rules formalising the selection of patients for clinical trials taken from the clinicaltrials.gov database. We demonstrate how high-level queries can be answered by Ontop-temporal to identify patients eligible for the trials.},
	urldate = {2024-12-12},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Güzel Kalayci, Elem and Xiao, Guohui and Ryzhikov, Vladislav and Kalayci, Tahir Emre and Calvanese, Diego},
	month = oct,
	year = {2018},
	pages = {1927--1930},
}

@inproceedings{bagosi_ontop_2014,
	address = {Berlin, Heidelberg},
	title = {The {Ontop} {Framework} for {Ontology} {Based} {Data} {Access}},
	isbn = {978-3-662-45495-4},
	doi = {10.1007/978-3-662-45495-4_6},
	abstract = {Ontology Based Data Access (OBDA) [4] is a paradigm of accessing data trough a conceptual layer. Usually, the conceptual layer is expressed in the form of an RDF(S) [10] or OWL [15] ontology, and the data is stored in relational databases.},
	language = {en},
	booktitle = {The {Semantic} {Web} and {Web} {Science}},
	publisher = {Springer},
	author = {Bagosi, Timea and Calvanese, Diego and Hardi, Josef and Komla-Ebri, Sarah and Lanti, Davide and Rezk, Martin and Rodríguez-Muro, Mariano and Slusnys, Mindaugas and Xiao, Guohui},
	editor = {Zhao, Dongyan and Du, Jianfeng and Wang, Haofen and Wang, Peng and Ji, Donghong and Pan, Jeff Z.},
	year = {2014},
	pages = {67--77},
}

@inproceedings{rodriguez-muro_ontology-based_2013,
	address = {Berlin, Heidelberg},
	title = {Ontology-{Based} {Data} {Access}: {Ontop} of {Databases}},
	isbn = {978-3-642-41335-3},
	shorttitle = {Ontology-{Based} {Data} {Access}},
	doi = {10.1007/978-3-642-41335-3_35},
	abstract = {We present the architecture and technologies underpinning the OBDA system Ontop and taking full advantage of storing data in relational databases. We discuss the theoretical foundations of Ontop: the tree-witness query rewriting, \${\textbackslash}mathcal\{T\}\$-mappings and optimisations based on database integrity constraints and SQL features. We analyse the performance of Ontop in a series of experiments and demonstrate that, for standard ontologies, queries and data stored in relational databases, Ontop is fast, efficient and produces SQL rewritings of high quality.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2013},
	publisher = {Springer},
	author = {Rodríguez-Muro, Mariano and Kontchakov, Roman and Zakharyaschev, Michael},
	editor = {Alani, Harith and Kagal, Lalana and Fokoue, Achille and Groth, Paul and Biemann, Chris and Parreira, Josiane Xavier and Aroyo, Lora and Noy, Natasha and Welty, Chris and Janowicz, Krzysztof},
	year = {2013},
	keywords = {Canonical Model, Conjunctive Query, Database Schema, Integrity Constraint, Relational Database},
	pages = {558--573},
}

@book{schied_connecting_2010,
	title = {Connecting {Semantic} {Mediawiki} to different {Triple} {Stores} {Using} {RDF2Go}},
	volume = {632},
	abstract = {This article describes a generic triple store connector for the popular Semantic MediaWiki software to be used with different triple stores like Jena or Sesame. Using RDF2Go as an abstraction layer it is possible to easily exchange triple stores. This ongoing work is part of the opendrugwiki project, a semantic wiki for distributed pharmaceutical research groups.},
	author = {Schied, Manfred and Köstlbacher, Anton and Wolff, Christian},
	month = jan,
	year = {2010},
	note = {Journal Abbreviation: CEUR Workshop Proceedings
Publication Title: CEUR Workshop Proceedings},
}

@misc{noauthor_ontological_nodate,
	title = {Ontological {Modeling} · {Ontological} {Modeling} {Language} {Specification}},
	url = {https://omf.gitbooks.io/ontological-modeling-language-specification/content/OntologicalModeling.html},
	urldate = {2024-12-10},
}

@article{carvalho_oml_2011,
	title = {{OML}: {A} {Scripting} {Approach} for {Manipulating} {Ontologies}},
	shorttitle = {{OML}},
	abstract = {There are different definitions for ontologies. Different knowledge areas tend to define ontologies in a different way. For computer science, an ontology can be used to describe, in a well defined and structured way, knowledge about a specific domain. These artifacts store rich information that can be reasoned about, this information can also be target of many structured processing functions. There is a diversity of programs that can be implemented to take advantage of these features and produce applications in every area of knowledge. The Ontology Manipulation Language (OML) is a Domain Specific Language (DSL) designed to describe and execute operations that reason about ontologies. These reasoning operations can be used to manipulate and maintain the current information in the ontology, infer new knowledge or concepts, or even produce any kind of side effect. OML is a simple and descriptive language, yet it is powerful enough to implement complex operations or reasoning engines in a clear and efficient way. To actually run programs written in OML a standalone compiler is available, as well as a mechanism for embedding OML programs in a generic programming language. This allows the quick development of applications that make use of ontologies, by describing ontology related operations in wove OML snippets throughout the code. This mechanism has proven to be a very effective and clear approach for taking advantage of adopting ontologies to represent information, while maintaining the implicit advantages of using a general-goal programming language.},
	journal = {CISTI},
	author = {Carvalho, Nuno and Almeida, José and Simões, Alberto},
	month = jan,
	year = {2011},
}

@misc{noauthor_kimball_2024,
	title = {Kimball lifecycle},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Kimball_lifecycle&oldid=1251712675},
	abstract = {The Kimball lifecycle is a methodology for developing data warehouses, and has been developed by Ralph Kimball and a variety of colleagues. The methodology "covers a sequence of high level tasks for the effective design, development and deployment" of a data warehouse or business intelligence system. It is considered a "bottom-up" approach to data warehousing as pioneered by Ralph Kimball, in contrast to the older "top-down" approach pioneered by Bill Inmon.},
	language = {en},
	urldate = {2024-12-10},
	journal = {Wikipedia},
	month = oct,
	year = {2024},
	note = {Page Version ID: 1251712675},
}

@misc{noauthor_dimensional_2024,
	title = {Dimensional modeling},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Dimensional_modeling&oldid=1258172888},
	abstract = {Dimensional modeling (DM) is part of the Business Dimensional Lifecycle methodology developed by Ralph Kimball which includes a set of methods, techniques and concepts for use in data warehouse design.: 1258–1260   The approach focuses on identifying the key business processes within a business and modelling and implementing these first before adding additional business processes, as a bottom-up approach.: 1258–1260   An alternative approach from Inmon advocates a top down design of the model of all the enterprise data using tools such as entity-relationship modeling (ER).: 1258–1260},
	language = {en},
	urldate = {2024-12-10},
	journal = {Wikipedia},
	month = nov,
	year = {2024},
	note = {Page Version ID: 1258172888},
}

@misc{shaabani_practical_2023,
	title = {Practical {Introduction} to {Data} {Vault} {Modeling}},
	url = {https://medium.com/@nuhad.shaabani/practical-introduction-to-data-vault-modeling-1c7fdf5b9014},
	abstract = {The Data Vault modeling is used to model the enterprise Data Warehouse Core layer. The model is suitable for multi-source environments…},
	language = {en},
	urldate = {2024-12-10},
	journal = {Medium},
	author = {Shaabani, Nuhad},
	month = jul,
	year = {2023},
}

@misc{noauthor_what_2022,
	title = {What is a {Data} {Vault}?},
	url = {https://www.databricks.com/glossary/data-vault},
	abstract = {A data vault is a data modeling design pattern used to build a data warehouse for enterprise-scale analytics.},
	language = {en-US},
	urldate = {2024-12-10},
	journal = {Databricks},
	month = apr,
	year = {2022},
}

@misc{noauthor_data_2024,
	title = {Data vault modeling},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Data_vault_modeling&oldid=1250247924},
	abstract = {Datavault or data vault modeling is a database modeling method that is designed to provide long-term historical storage of data coming in from multiple operational systems. It is also a method of looking at historical data that deals with issues such as auditing, tracing of data, loading speed and resilience to change as well as emphasizing the need to trace where all the data in the database came from. This means that every row in a data vault must be accompanied by record source and load date attributes, enabling an auditor to trace values back to the source. The concept was published in 2000 by Dan Linstedt.
Data vault modeling makes no distinction between good and bad data ("bad" meaning not conforming to business rules). This is summarized in the statement that a data vault stores "a single version of the facts" (also expressed by Dan Linstedt as "all the data, all of the time") as opposed to the practice in other data warehouse methods of storing "a single version of the truth" where data that does not conform to the definitions is removed or "cleansed". A data vault enterprise data warehouse provides both; a single version of facts and a single source of truth.
The modeling method is designed to be resilient to change in the business environment where the data being stored is coming from, by explicitly separating structural information from descriptive attributes. Data vault is designed to enable parallel loading as much as possible, so that very large implementations can scale out without the need for major redesign.
Unlike the star schema (dimensional modelling) and the classical relational model (3NF), data vault and anchor modeling are well-suited for capturing changes that occur when a source system is changed or added, but are considered advanced techniques which require experienced data architects. Both data vaults and anchor models are entity-based models, but anchor models have a more normalized approach.},
	language = {en},
	urldate = {2024-12-10},
	journal = {Wikipedia},
	month = oct,
	year = {2024},
	note = {Page Version ID: 1250247924},
}

@misc{noauthor_what_nodate-1,
	title = {What is a {Semantic} {Layer}? {A} {Detailed} {Guide}},
	shorttitle = {What is a {Semantic} {Layer}?},
	url = {https://www.datacamp.com/blog/semantic-layer},
	abstract = {Discover what semantic layers are and how they help data quality and consistency. Learn how they boost self-service analytics by providing user-friendly access.},
	language = {en},
	urldate = {2024-12-10},
}

@misc{noauthor_get_nodate,
	title = {Get {Started} with {Citus} – {Distributed} {PostgreSQL} {At} {Any} {Scale}},
	url = {https://www.citusdata.com/getting-started/},
	abstract = {How to get started with the Citus database, so you can use PostgreSQL at any scale. Includes links to docs, videos, demos, tutorials, use case guides, where to download, how to try in the cloud. Also, links to blog posts about what’s new, including Citus 11, Postgres 15, and more.},
	language = {en},
	urldate = {2024-12-10},
	journal = {Citus Data},
}

@misc{noauthor_composable_2024,
	title = {Composable data management at {Meta}},
	url = {https://engineering.fb.com/2024/05/22/data-infrastructure/composable-data-management-at-meta/},
	abstract = {In recent years, Meta’s data management systems have evolved into a composable architecture that creates interoperability, promotes reusability, and improves engineering efficiency.  We’re sharing …},
	language = {en-US},
	urldate = {2024-12-09},
	journal = {Engineering at Meta},
	month = may,
	year = {2024},
}

@inproceedings{carneiro_x-meta_2002,
	title = {X-{META}: {A} {Methodology} for {Data} {Warehouse} {Design} with {Metadata} {Management}},
	shorttitle = {X-{META}},
	abstract = {Date Warehousing is a powerful tool for supporting decision-making processes in modern corporations. However, developing a Data Warehouse (DW) is a complex and costly activity. It requires strategies, which should be specific to the characteristics and needs of the organization where it will be introduced. This work presents a DW development methodology suitable to organizational environments which need Data Warehousing support as a strategic requirement, but have to use the internal staff which has no expertise in DW development. Moreover, a strategy for creating and managing metadata in an integrated way to t he DW development process is proposed, in order to capture the organizational knowledge and minimize the problems which can be caused by the mobility of employees within and between organizations.},
	author = {Carneiro, Liane and Brayner, Angelo},
	month = jan,
	year = {2002},
	pages = {13--22},
}

@inproceedings{huang_meta-data_2000,
	title = {A {Meta}-{Data} {Management} {System} for {Data} {Warehouse}},
	url = {https://www.semanticscholar.org/paper/A-Meta-Data-Management-System-for-Data-Warehouse-Huang-Hung/823c2c08cccf3e9baa84cba1d3637c461ddb2c9a},
	abstract = {A data warehouse is simply a single, complete, and consistent store of data obtain from a variety of sources and made available to end users in a way they can understand and use in a business context. To manage and maintain the heterogeneous data source and huge amount data of a data warehouse, much research has been done in the topic called Meta-Data management system. Current research for Meta-Data management systems is focused on the management of the heterogeneous database schema but not system performance. This paper describes a new Meta-Data management system architecture, which is focused on the uniform Meta-Data model and the query performance. The new system includes a repository to store an integrated database schema which is constructed from the different source database schema and a proxy database server which is to store used data by following the structure of the integrated database schema. This new architecture can increase the query performance and reduce the loading to manage the huge amount data for a data warehouse.},
	urldate = {2024-12-09},
	author = {Huang, Shih-Ming and Hung, T. and Fong, J.},
	year = {2000},
}

@misc{noauthor_apache_nodate,
	title = {Apache {ORC} • {High}-{Performance} {Columnar} {Storage} for {Hadoop}},
	url = {https://orc.apache.org/},
	urldate = {2024-12-09},
}

@misc{meta_data_2023,
	title = {Data engineering at {Meta}: {High}-{Level} {Overview} of the internal tech stack},
	shorttitle = {Data engineering at {Meta}},
	url = {https://medium.com/@AnalyticsAtMeta/data-engineering-at-meta-high-level-overview-of-the-internal-tech-stack-a200460a44fe},
	abstract = {This article provides an overview of the internal tech stack that we use on a daily basis as data engineers at Meta. The idea is to shed…},
	language = {en},
	urldate = {2024-12-09},
	journal = {Medium},
	author = {Meta, Analytics at},
	month = oct,
	year = {2023},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {A} {Meta}-{Data} {Management} {System} for {Data} {Warehouse}},
	url = {https://www.researchgate.net/publication/228805447_A_Meta-Data_Management_System_for_Data_Warehouse},
	abstract = {PDF {\textbar} A data warehouse is simply a single, complete, and consistent store of data obtain from a variety of sources and made available to end users in a... {\textbar} Find, read and cite all the research you need on ResearchGate},
	language = {en},
	urldate = {2024-12-09},
	journal = {ResearchGate},
}

@misc{noauthor_data_nodate,
	title = {Data warehousing and analytics infrastructure at {Facebook}. - {Meta} {Research}},
	url = {https://research.facebook.com/publications/data-warehousing-and-analytics-infrastructure-at-facebook/},
	abstract = {Scalable analysis on large data sets has been core to the functions of a number of teams at Facebook - both engineering and non-engineering. Apart from ad hoc analysis of data and creation of business intelligence dashboards by analysts across the company, a number of Facebook's site features are also based on analyzing large data sets.},
	language = {fr},
	urldate = {2024-12-09},
	journal = {Meta Research},
}

@misc{noauthor_metadata_nodate,
	title = {Metadata {Data} {Warehouse}: {Understanding} {Metadata} and its {Role} in {Data} {Warehouse}},
	shorttitle = {Metadata {Data} {Warehouse}},
	url = {https://www.sprinkledata.com/blogs/metadata-data-warehouse-understanding-metadata-and-its-role-in-data-warehouse},
	abstract = {Explore the significance of metadata in data warehousing. Learn about its types, uses, challenges, and best practices for effective management within a data warehouse environment},
	language = {en-US},
	urldate = {2024-12-09},
}

@misc{humbertohp_exploring_2024,
	title = {Exploring the {Modern} {Data} {Warehouse}},
	url = {https://learn.microsoft.com/en-us/data-engineering/playbook/solutions/modern-data-warehouse/},
	abstract = {The Modern Data Warehouse (MDW) is a common architectural pattern t build analytical data pipelines in a cloud-first environment.},
	language = {en-us},
	urldate = {2024-12-09},
	author = {humbertohp},
	month = may,
	year = {2024},
}

@misc{noauthor_what_nodate-2,
	title = {What is a data warehouse? {\textbar} {Definition}, components, architecture},
	shorttitle = {What is a data warehouse?},
	url = {https://www.sap.com/products/technology-platform/datasphere/what-is-a-data-warehouse.html},
	abstract = {A data warehouse (DW) is a digital storage system that connects large amounts of data from different sources to feed BI, reporting, and analytics.},
	language = {English},
	urldate = {2024-12-09},
	journal = {SAP},
}

@article{berkowitz_why_2018,
	title = {Why {Meta}-{Organizations} {Matter}: {A} {Response} to {Lawton} et al. and {Spillman}},
	volume = {27},
	issn = {1056-4926},
	shorttitle = {Why {Meta}-{Organizations} {Matter}},
	url = {https://doi.org/10.1177/1056492617712895},
	doi = {10.1177/1056492617712895},
	abstract = {In a recent issue in this journal, Lawton et al. and Spillman argue for the importance of studying trade associations, also referred to with the broader term meta-organization. They discuss why meta-organizations matter and why more research is needed on the topic. We fully concur with the authors that meta-organizations constitute an inflating, diverse, and undeniable phenomenon of collective action among organizations and that collective scholarly efforts are necessary to improve our understanding of meta-organizations in their multiplicity. In this article, we shed some light on a body of work already investigating the matter. They constitute what we call the “European School” of meta-organization. We show the relevance of this recent European work for the US–UK-oriented trade association research and aim to bridge the gap between these research traditions by proposing a common research agenda on key topics of resources, forms’ differentiation, coopetition, and their role in sustainability governance.},
	language = {en},
	number = {2},
	urldate = {2024-11-21},
	journal = {Journal of Management Inquiry},
	author = {Berkowitz, Héloïse and Bor, Sanne},
	month = apr,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	pages = {204--211},
}

@article{cropper_bounding_2018,
	title = {({Un})bounding the {Meta}-{Organization}: {Co}-{Evolution} and {Compositional} {Dynamics} of a {Health} {Partnership}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3387},
	shorttitle = {({Un})bounding the {Meta}-{Organization}},
	url = {https://www.mdpi.com/2076-3387/8/3/42},
	doi = {10.3390/admsci8030042},
	abstract = {In their treatise on meta-organization, Ahrne and Brunsson theorize a distinctive organizational form, the association of organizations. Meta-organizations have the properties of formal organizations—boundaries set by determinations of membership, goals, a centre of authority, and ways of monitoring and sanctioning member behaviors. The theory draws a strong distinction between meta-organizations and networks, suggesting that similarity among members is the primary characteristic of meta-organizations, whereas networks signify complementarity and difference. Meta-organizations serve and are governed by their members, though the meta-organization itself may develop its own agency and may regulate its members. It is on this basis that Ahrne and Brunsson develop an account of the dynamics of meta-organizations, placing less emphasis on external sources of change than on the internal relationships between members and the meta-organization itself. This paper appraises the theory of meta-organizations, using a case study of Partners in Paediatrics, a subscription association of health care organizations, as the empirical reference point. Data about this partnership’s membership and its activities are drawn from 12 ‘annual reports’ covering a 17-year period. Focusing, particularly, on the membership composition of the Partnership and its relationship to the changing environment, the case analysis traces the changing character and circumstances of the Partnership, identifying four distinct phases, and raising questions for meta-organization theory and its account of meta-organization dynamics.},
	language = {en},
	number = {3},
	urldate = {2024-12-02},
	journal = {Administrative Sciences},
	author = {Cropper, Steve and Bor, Sanne},
	month = aug,
	year = {2018},
	pages = {42},
}

@book{ahrne_meta-organizations_2008,
	title = {Meta-organizations},
	isbn = {978-1-84844-265-8},
	abstract = {A growing number of organizations are meta-organizations; rather than individuals they have other organizations as their members. This comprehensive book explains, in-depth, the unique way in which meta-organizations function, how they differ from organizations with individual membership, and how they are crucial agents in the process of globalization.},
	language = {en},
	publisher = {Edward Elgar Publishing},
	author = {Ahrne, Göran and Brunsson, Nils},
	month = jan,
	year = {2008},
	keywords = {Business \& Economics / Management},
}

@book{aldrich_organizations_1999,
	title = {Organizations {Evolving}},
	isbn = {978-0-8039-8919-1},
	abstract = {Winner of the 2000 Max Weber prize, awarded by the Section on Organizations, Occupations, and Work, of the American Sociological Association, for the best book on organizations published in the past 3 years!   `This book is an exceptional accomplishment and is compulsory reading for all organizational researchers'- Hayagreeva Rao, Emory University  `Organizations Evolving is precisely what this book is about. In a richly textured way, Howard Aldrich gives the reader a distinctive feel for the subject and a way to think about and understand emergence and change in organizations. [The book] is informative and engaging. It is playful and rigorous. It is scholarly and quite prac},
	language = {en},
	publisher = {SAGE},
	author = {Aldrich, Howard},
	month = oct,
	year = {1999},
	keywords = {Business \& Economics / Business Communication / General, Business \& Economics / Business Ethics},
}

@book{howard_organizations_nodate,
	title = {Organizations {Evolving}},
	url = {https://books.google.fr/books?hl=en&lr=&id=pdci-4om5rIC&oi=fnd&pg=PP1&dq=Aldrich,+H.+(1999).+Organizations+evolving.+London:+Sage.&ots=DEV6prbE-f&sig=3rcPoOg52wilgZYxFhAlJKnkcFo#v=onepage&q=Aldrich%2C%20H.%20(1999).%20Organizations%20evolving.%20London%3A%20Sage.&f=false},
	urldate = {2024-12-02},
	author = {Howard, Aldrich},
}

@article{ahrne_social_1994,
	title = {Social {Organizations} : {Interaction} {Inside}, {Outside} and {Between} {Organizations}},
	shorttitle = {Social {Organizations}},
	url = {https://www.torrossa.com/en/resources/an/5018559},
	abstract = {Purchase online the PDF of Social Organizations, Ahrne, Goran - SAGE Publications Ltd - E-book},
	language = {en},
	urldate = {2024-12-02},
	author = {Ahrne, Goran},
	year = {1994},
	note = {Publisher: SAGE Publications Ltd},
	pages = {1--192},
}

@article{kaufman_organizations_1959,
	title = {Organizations. {By} {James} {G}. {March} and {Herbert} {A}. {Simon} with the collaboration of {Harold} {Guetzkow}. ({New} {York}: {John} {Wiley} and {Sons}, {Inc}.; {London}: {Chapman} and {Hall}, {Ltd}., 1958. {Pp}. xi, 262. \$6.00.)},
	volume = {53},
	issn = {1537-5943, 0003-0554},
	shorttitle = {Organizations. {By} {James} {G}. {March} and {Herbert} {A}. {Simon} with the collaboration of {Harold} {Guetzkow}. ({New} {York}},
	url = {https://www.cambridge.org/core/journals/american-political-science-review/article/abs/organizations-by-marchjames-g-and-simonherbert-a-with-the-collaboration-of-harold-guetzkow-new-york-john-wiley-and-sons-inc-london-chapman-and-hall-ltd-1958-pp-xi-262-600/6017E27AAE077C170FE0805D5976118F},
	doi = {10.2307/1952084},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0003055400075699/resource/name/firstPage-S0003055400075699a.jpg},
	language = {en},
	number = {4},
	urldate = {2024-12-02},
	journal = {American Political Science Review},
	author = {Kaufman, Herbert},
	month = dec,
	year = {1959},
	pages = {1127--1129},
}

@book{march_organizations_1993,
	title = {Organizations},
	isbn = {978-0-631-18631-1},
	abstract = {Everything you ever wanted to know about growing grapes March and Simon's Organizations has become a classic in the field of organizational management for its broad scope and depth of information. Written by two of the most prominent experts in the field, this book offers invaluable insight on all aspects of organizational culture through deep discussion of organization theory. The definitive reference for topics including bounded rationality, satisficing, inducement/contribution balances, attention focus, uncertainty absorption and more, this seminal text offers authoritative insight with a practical grounding in the field.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {March, James G. and Simon, Herbert A.},
	month = may,
	year = {1993},
	note = {Google-Books-ID: FbBJEAAAQBAJ},
	keywords = {Business \& Economics / General, Business \& Economics / Management, Business \& Economics / Organizational Behavior},
}

@misc{noauthor_study_nodate,
	title = {The {Study} of {Organizations} and {Organizing} {Since} 1945 - {James} {G}. {March}, 2007},
	url = {https://journals.sagepub.com/doi/abs/10.1177/0170840607075277},
	urldate = {2024-12-02},
}

@article{seran_information_2022,
	series = {International {Conference} on {Industry} {Sciences} and {Computer} {Science} {Innovation}},
	title = {Information systems’ adoption in meta-organizations},
	volume = {204},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S187705092200792X},
	doi = {10.1016/j.procs.2022.08.054},
	abstract = {Despite the increase presence and importance of meta-organizations in the modern society, little is known about the specificity of the inter-organizational information systems in this adopter configuration. Using an in-depth analysis of two case studies of meta-organizational information systems adoption – the French cooperative banks Caisses d'Epargnes and Crédit Agricole, we identify the main stages and challenges of the information system adoption, as well as the boundary-spanning roles, activities and objects that facilitate the implementation and coordination of these complex projects.},
	urldate = {2024-11-21},
	journal = {Procedia Computer Science},
	author = {Seran, Thuy and Gurău, Călin and Pellegrin-Boucher, Estelle},
	month = jan,
	year = {2022},
	keywords = {challenges of implementation, coordinating mechanisms, information system adoption, meta-organizations, stages},
	pages = {440--447},
}

@article{saniossian_meta-organizations_2022,
	title = {Meta-{Organizations} in the {Making}. {A} {Multiple} {Case} {Study} of {Multi}-{Stakeholder} {Meta}-{Organizations} for {Social} {Innovation}},
	volume = {25},
	url = {https://shs.cairn.info/revue-management-2022-2-page-27},
	language = {en},
	number = {2},
	urldate = {2024-11-21},
	journal = {M@n@gement},
	author = {Saniossian, Jennifer and Lecocq, Xavier and Beaucourt, Christel},
	year = {2022},
	note = {Publisher: AIMS},
	pages = {27--44},
}

@article{berkowitz_meta-organizations_2022,
	title = {Meta-{Organizations}: {A} {Clarification} and a {Way} {Forward}},
	volume = {25},
	shorttitle = {Meta-{Organizations}},
	url = {https://shs.cairn.info/revue-management-2022-2-page-1},
	language = {en},
	number = {2},
	urldate = {2024-11-21},
	journal = {M@n@gement},
	author = {Berkowitz, Héloïse and Brunsson, Nils and Grothe-Hammer, Michael and Sundberg, Mikaela and Valiorgue, Bertrand},
	year = {2022},
	note = {Publisher: AIMS},
	pages = {1--9},
}

@techreport{marlowe_nasa_2022,
	title = {{NASA} {Enterprise} {Digital} {Transformation} {Initiative} {Strategic} {Framework} \& {Implementation} {Approach}},
	url = {https://ntrs.nasa.gov/citations/20220018538},
	abstract = {Since 1958, NASA has delivered its  enduring bold purpose, characterized in the 2022 NASA Strategic Plan as a mission to discover, explore, innovate, and advance solutions to the problems of flight, within and outside the Earth’s atmosphere, for the benefit of humankind. The NASA Strategic Plan also recognizes that this mission will be delivered differently as it looks to a future marked by radical global change, which is in part being driven by digital advances. For this reason, in late 2020 NASA established an Enterprise Digital Transformation (DT) agency-level strategic initiative to accelerate and coordinate leveraging digital advances to transform the way the Agency works, the experience of its workforce and the agility of its workplace. This paper documents NASA’s DT strategic framework and associated implementation approach, with the DT strategic initiative serving to ignite, connect, integrate, and facilitate DT progress across a federated organizational operating model.},
	urldate = {2024-11-13},
	author = {Marlowe, Jill M. and Haymes, Christina L. and Murphy, Patrick L.},
	month = dec,
	year = {2022},
	note = {NTRS Author Affiliations: National Aeronautics and Space Administration, Langley Research Center
NTRS Document ID: 20220018538
NTRS Research Center: Headquarters (HQ)},
	keywords = {Administration and Management},
}

@misc{unita_unita_nodate,
	title = {{UNITA} - {Universitas} {Montium}},
	url = {http://www.univ-unita.ubi.pt},
	abstract = {UNITA - We are an alliance of six comprehensive research universities from five countries with different sizes and trajectories gathering together more than 160 000 students and 13 000 staff members.},
	language = {pt},
	urldate = {2024-11-12},
	journal = {UNITA - Universitas Montium},
	author = {UNITA},
}

@article{krabina_building_2023,
	title = {Building a {Knowledge} {Graph} for the {History} of {Vienna} with {Semantic} {MediaWiki}},
	volume = {76},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826822000555},
	doi = {10.1016/j.websem.2022.100771},
	abstract = {While research on semantic wikis is declining, Semantic MediaWiki (SMW) can still play an important role in the emerging field of knowledge graph curation. The Vienna History Wiki, a large knowledge base curated by the city government in collaboration with other institutions and the general public, provides an ideal use case for demonstrating strengths and weaknesses of SMW as well as discussing the challenges of co-curation in a cultural heritage setting. This paper describes processes like collaborative editing, interlinking unique identifiers on the web, sharing data with Wikidata, making use of Schema.org, and other ontologies. It presents insights from a user survey, access statistics, and a knowledge graph analysis. This work contributes to the scarce research in wiki usage outside of the Wikipedia ecosystem as well as to the field of community-based knowledge graph curation. The availability of a now significantly improved RDF representation indicates future directions for research and practice.},
	urldate = {2024-11-12},
	journal = {Journal of Web Semantics},
	author = {Krabina, Bernhard},
	month = apr,
	year = {2023},
	keywords = {Cultural heritage, Digital curation, Knowledge graphs, Linked data, Open government, Semantic MediaWiki, Semantic wikis, Vienna History Wiki},
	pages = {100771},
}

@article{ahrne_organizations_2005,
	title = {Organizations and meta-organizations},
	volume = {21},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09565221},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0956522105000813},
	doi = {10.1016/j.scaman.2005.09.005},
	language = {en},
	number = {4},
	urldate = {2024-11-12},
	journal = {Scandinavian Journal of Management},
	author = {Ahrne, Göran and Brunsson, Nils},
	month = dec,
	year = {2005},
	pages = {429--449},
}

@article{ahrne_paradox_2016,
	title = {The {Paradox} of {Organizing} {States}: {A} {Meta}-{Organization} {Perspective} on {International} {Organizations}},
	volume = {7},
	doi = {https://doi.org/10.1111/emre.12076},
	abstract = {In order to conceptualize international governmental organizations (IGOs) as powerful actors, international relations scholars increasingly resort to approaches that present these organizations as behaving like modern corporations or bureaucracies. Although we agree with the underlying assumption that it is useful to understand IGOs as organizations, we find these approaches only give partial answers. We argue that the key to a more complete understanding of international organizations is to conceptualize them not as standard forms of organizations with individuals as their members but as meta-organizations comprising organized actors as members. Meta-organizations are paradoxical constructions: autonomous actors with autonomous actors as members. An international organization is permanently competing for actorhood with its member states, and this competition has far-reaching implications for the ways they perform as agents of global governance. Meta-organization theory explains why international organizations are less powerful actors than standard organizations are-why it is more difficult for them to make decisions and to achieve coordination and organizational action. Yet international organizations are strong in other respects. Meta-organization theory explains why they are easily established, why they can place strong demands on new members, and why their existing members are slowly transformed by their membership. Overall, many international organizations are influential but in a different way than suggested by standard theories of organizations.},
	number = {1},
	journal = {JIOS},
	author = {Ahrne, Göran and Brunsson, Nils},
	year = {2016},
}

@article{hat_what_nodate,
	title = {What {Every} {Programmer} {Should} {Know} {About} {Memory}},
	abstract = {As CPU cores become both faster and more numerous, the limiting factor for most programs is now, and will be for some time, memory access. Hardware designers have come up with ever more sophisticated memory handling and acceleration techniques–such as CPU caches–but these cannot work optimally without some help from the programmer. Unfortunately, neither the structure nor the cost of using the memory subsystem of a computer or the caches on CPUs is well understood by most programmers. This paper explains the structure of memory subsystems in use on modern commodity hardware, illustrating why CPU caches were developed, how they work, and what programs should do to achieve optimal performance by utilizing them.},
	language = {en},
	author = {Hat, Ulrich Drepper Red},
}

@article{huisman_revisiting_2023,
	title = {Revisiting organizational actorhood in higher education: the role of legitimate agency},
	volume = {87},
	shorttitle = {Revisiting organizational actorhood in higher education},
	doi = {10.1007/s10734-023-01055-3},
	abstract = {This paper proposes an extension of the concept of organizational actorhood. This concept is very useful to understand contemporary higher education institutions, but it pictures these organizations as relatively passive, subject to normative pressures. The conceptualization lacks attention to dynamic agency of higher education institution. Using notions of accountability, legitimacy and identity, a reconceptualization is proposed. That reconceptualization stresses the agentic potential of higher education institutions to pro-actively test the boundaries of legitimacy and accountability and its capacity to continuously (re)negotiate its position in institutional contexts. Suggestions are offered for further research.},
	journal = {Higher Education},
	author = {Huisman, Jeroen and Burgoa, Emmanuel},
	month = may,
	year = {2023},
	pages = {1--15},
}

@incollection{dumay_introduction_2017,
	address = {New York ; London},
	title = {An introduction to interventionist research in accounting},
	isbn = {978-1-138-93967-7},
	url = {http://www.scopus.com/inward/record.url?scp=85044261451&partnerID=8YFLogxK},
	abstract = {The purpose of this chapter is to introduce interventionist research (hereafter IVR) and some of its peculiarities to accounting researchers who may not be familiar with this research approach. The lead author’s interest in, and knowledge of, IVR stems from his own experiences, both as an accounting academic and as an independent business consultant working in a variety of industries. During a fifteen-year career in consulting, he helped small and medium enterprises install accounting information systems, and trained owners and managers in how to integrate financial controls into their businesses. Additionally, he has experience working in a large international telecommunications company as a finance and accounting project manager. These skills and experiences mean that he can work directly with organizations on their day-to-day accounting and management control issues.},
	urldate = {2024-07-05},
	booktitle = {The {Routledge} companion to qualitative accounting research methods},
	publisher = {Routledge, Taylor and Francis Group},
	author = {Dumay, John and Baard, Vicki},
	editor = {Haynes, Kathryn and Hoque, Zahirul and Parker, Lee D. and Covaleski, Mark A.},
	year = {2017},
	doi = {10.4324/9781315674797-16},
	pages = {265--283},
}

@article{loudcher_vers_2011,
	title = {Vers l'{OLAP} sémantique pour l'analyse en ligne des données complexes},
	abstract = {L'analyse en ligne OLAP permet une navigation interactive dans les données, une visualisation rapide de l'information et une exploration de la structure multidimensionnelle des données. Une des limites est de se restreindre à des aspects exploratoires et navigationnels. De plus, avec l'avènement des données complexes (données multi-format et/ou multi-structure et/ou multi-source et/ou multi-modale et/ou multi-version), l'analyse en ligne doit s'adapter à la nature spécifique de ces données tout en gardant l'esprit de l'OLAP. Les opérateurs OLAP sont définis pour des données classiques et sont souvent inadaptés quand il s'agit de données complexes par exemple composées de textes, images, son ou vidéos. Les limites de l'OLAP ainsi que la spécificité des données complexes nécessitent une évolution ou adaptation de l'OLAP. Il devient nécessaire de : (1) enrichir les possibilités de l'analyse OLAP en la dotant de nouvelles possibilités ; (2) créer une analyse en ligne adaptée aux données complexes ; (3) faire évoluer l'OLAP vers une analyse sémantique des données. Dans cette vaste problématique, nous choisissons de traiter les questions d'agrégation et visualisation des données complexes, de réorganisation du cube pour identifier des régions d'analyse intéressantes, et d'étendre l'OLAP à des possibilités d'explication et de prédiction. Pour toutes ces questions, nous essayons également de tenir compte de la sémantique véhiculée par les données. Pour apporter des premières solutions, nous orientons vers une combinaison des principes de l'OLAP, de la fouille de données et de la recherche d'information. Afin d'introduire une analyse explicative dans l'OLAP, nous faisons une recherche guidée de règles d'association dans le cube. Cela nous conduit à modifier la définition du support et de la confiance d'une règle. Les arbres de régression nous permettent de proposer à l'utilisateur de faire de la prédiction dans le cube et d'avoir ainsi une démarche de type What If Analysis. Pour l'analyse des données complexes, deux méthodes factorielles (AFC et ACM) rendent possible la visualisation des faits dans un cube et la détection de régions intéressantes en réorganisant les dimensions du cube. Nous proposons également une agrégation sémantique des faits et une nouvelle hiérarchie de dimension construite automatiquement grâce aux principes d'une méthode de classification (CAH). Nos propositions sont une première démonstration de la faisabilité de combiner l'OLAP à d'autres techniques comme la fouille de données et la recherche d'information pour faire significativement évoluer l'analyse en ligne et s'adapter aux données complexes. L'OLAP a commencé à s'adapter à leur structure et à leur spécificité (XOLAP - XML OLAP, SOLAP - spatial OLAP). Mais il faut aller au delà et nous pensons qu'un des défis est d'extraire et d'analyser (en ligne) la sémantique contenue dans les données complexes. Ce point constitue un véritable verrou scientifique mais qui est que partiellement abordé par la communauté scientifique. Il faudrait également identifier tous les problèmes posés par les données complexes et ce quels que soient leur nature, contexte ou spécificités. Nous voulons poursuivre nos travaux dans cette voie et faire évoluer l'OLAP vers une nouvelle génération d'analyse en ligne : l'OLAP sémantique. Les problèmes majeurs à traiter seront comment : (1) modéliser toutes les formes de données complexes, leur sémantique et leurs liens ; (2) analyser en ligne les données complexes ; (3) Intégrer les connaissances de l'utilisateur dans le processus de l'analyse ?},
	author = {Loudcher, Sabine},
	month = jun,
	year = {2011},
}

@phdthesis{diallo_architecture_2006,
	address = {Grenoble},
	title = {Une {Architecture} à base d'{Ontologies} pour la {Gestion} {Unifiées} des {Données} {Structurées} et non {Structurées}},
	url = {https://theses.hal.science/tel-00221392},
	school = {Université Grenoble Alpes},
	author = {Diallo, Gayo},
	year = {2006},
	keywords = {ANNOTATION DE DOCUMENTS, BRAIN DOMAIN, CERVEAU, DATA INTEGRATION, DOCUMENTS ANNOTATION, INFORMATION RETRIEVAL, INTÉGRATION DE DONNÉES, ONTOLOGIES, RECHERCHE D'INFORMATIONS, SEMANTIC WEB, WEB SÉMANTIQUE},
}

@article{stein_understanding_2012,
	address = {London, UK},
	title = {Understanding theory of change in international development},
	issn = {2051-0926},
	url = {http://www.lse.ac.uk/internationalDevelopment/research/JSRP/jsrp.aspx},
	abstract = {This paper is the first output from a collaborative research project between JSRP and The Asia Foundation (TAF). The paper reviews the concepts and common debates within the 'Theory of Change' literature, resulting from a detailed analysis of available donor, agency and expert guidance documents. A number of key issues are highlighted in the paper and these inform the collaborative research. Following this review of the literature, Stein and Valters undertook fieldwork in Sri Lanka and Nepal hosted by the local TAF office and further outputs are scheduled for publication in early 2013.},
	language = {en},
	urldate = {2024-07-04},
	journal = {Justice and Security Research Programme, International Development Department, London School of Economics and Political Science},
	author = {Stein, Danielle and Valters, Craig},
	month = aug,
	year = {2012},
	pages = {22},
}

@book{mars_towards_1995,
	address = {Amsterdam ; Washington D.C},
	title = {Towards very large knowledge bases: knowledge building \& knowledge sharing 1995},
	isbn = {978-90-5199-217-5},
	shorttitle = {Towards very large knowledge bases},
	publisher = {IOS Press},
	editor = {Mars, N. J. I.},
	year = {1995},
	note = {Meeting Name: International Conference on Building and Sharing Very Large-Scale Knowledge Bases},
	keywords = {Congresses, Database design, Database management},
}

@book{hofmann_rapidminer_2016,
	edition = {0},
	title = {{RapidMiner}: {Data} {Mining} {Use} {Cases} and {Business} {Analytics} {Applications}},
	isbn = {978-0-429-17109-3},
	shorttitle = {{RapidMiner}},
	url = {https://www.taylorfrancis.com/books/9781482205503},
	language = {en},
	urldate = {2024-10-30},
	publisher = {Chapman and Hall/CRC},
	editor = {Hofmann, Markus and Klinkenberg, Ralf},
	month = apr,
	year = {2016},
	doi = {10.1201/b16023},
}

@article{unesco_draft_2015,
	title = {Draft preliminary report concerning the preparation of a global convention on the recognition of higher education qualifications; 2015},
	url = {https://unesdoc.unesco.org/ark:/48223/pf0000234743},
	author = {{UNESCO}},
	year = {2015},
	pages = {34},
}

@article{roberts_critical_2010,
	title = {A critical review of interventionist research},
	volume = {7},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {1176-6093},
	url = {https://www.emerald.com/insight/content/doi/10.1108/11766091011034262/full/html},
	doi = {10.1108/11766091011034262},
	abstract = {Purpose
              The purpose of this paper is to further develop the epistemological base of interventionist research (IR) as a valid accounting and management research methodology, through the identification of intervention theory and an IR framework derived from social sciences. Moreover, this paper seeks to contribute to empirical knowledge of IR through a critical review of limited empirical evidence relating to intervention theory and the extant IR frameworks derived from action research.
            
            
              Design/methodology/approach
              Texts and academic journal papers that judiciously review intervention theory, intervention research frameworks were identified systematically; along with empirical research addressing theoretical and methodological deficiencies of IR and, providing evidence to inform practical considerations when undertaking IR.
            
            
              Findings
              The key findings include rare empirical evidence addressing theoretical shortcomings and application of intervention theory, an IR framework derived from social sciences with extremely limited use in accounting and management research, deficiencies in action research oriented frameworks labelled as alternative forms of IR, an alternate perspective to positivistic validity and reliability issues and other practical considerations to facilitate the conducting of IR.
            
            
              Originality/value
              The novelty of this paper lies in the diminution of the fragmented nature of IR that undermines its scientific value through the identification of an intervention theory and IR framework experiencing extremely limited use in accounting and management research, with the exception of a cross‐disciplinary (management accounting and information systems) doctoral study, optimising IR utilisation with greater degrees of validity and reliability and, finally, a proposed alternative research design for utilisation in IR.},
	language = {en},
	number = {1},
	urldate = {2024-10-30},
	journal = {Qualitative Research in Accounting \& Management},
	author = {Baard, Vicki},
	editor = {Roberts, Hanno},
	month = apr,
	year = {2010},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Action research, Research methods},
	pages = {13--45},
}

@article{prat_uml-based_2006,
	title = {A {UML}-based data warehouse design method},
	volume = {42},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923605001788},
	doi = {10.1016/j.dss.2005.12.001},
	abstract = {Data warehouses are a major component of data-driven decision support systems (DSS). They rely on multidimensional models. The latter provide decision makers with a business-oriented view to data, thereby easing data navigation and analysis via On-Line Analytical Processing (OLAP) tools. They also determine how the data are stored in the data warehouse for subsequent use, not only by OLAP tools, but also by other decision support tools. Data warehouse design is a complex task, which requires a systematic method. Few such methods have been proposed to date. This paper presents a UML-based data warehouse design method that spans the three design phases (conceptual, logical and physical). Our method comprises a set of metamodels used at each phase, as well as a set of transformations that can be semi-automated. Following our object orientation, we represent all the metamodels using UML, and illustrate the formal specification of the transformations based on OMG's Object Constraint Language (OCL). Throughout the paper, we illustrate the application of our method to a case study.},
	language = {en},
	number = {3},
	urldate = {2024-10-30},
	journal = {Decision Support Systems},
	author = {Prat, Nicolas and Akoka, Jacky and Comyn-Wattiau, Isabelle},
	month = dec,
	year = {2006},
	keywords = {Conceptual design, Data warehouse, Decision support, Logical design, On-Line Analytical Processing (OLAP), Physical design},
	pages = {1449--1473},
}

@article{vandor_addressing_2019,
	title = {Addressing {Grand} {Challenges} {Collectively}: {A} {Brief} {Introduction} to {Impact}-{Oriented} {Networks}},
	issn = {1556-5068},
	shorttitle = {Addressing {Grand} {Challenges} {Collectively}},
	url = {https://www.ssrn.com/abstract=3472979},
	doi = {10.2139/ssrn.3472979},
	language = {en},
	urldate = {2024-10-30},
	journal = {SSRN Electronic Journal},
	author = {Vandor, Peter and Leitner, Lukas and Millner, Reinhard and Hansen, Hinnerk},
	year = {2019},
}

@inproceedings{lahrmann_business_2011,
	address = {Kauai, HI},
	title = {Business {Intelligence} {Maturity}: {Development} and {Evaluation} of a {Theoretical} {Model}},
	isbn = {978-1-4244-9618-1},
	shorttitle = {Business {Intelligence} {Maturity}},
	url = {http://ieeexplore.ieee.org/document/5718882/},
	doi = {10.1109/HICSS.2011.90},
	abstract = {In order to identify and explore the strengths and weaknesses of business intelligence (BI) initiatives, managers in charge need to assess the maturity of their BI efforts. For this, a wide range of maturity models has been developed, but these models often focus on technical details and do not address the potential value proposition of BI. Based on an extensive literature review and an empirical study, we develop and evaluate a theoretical model of impact-oriented BI maturity. Building on established IS theories, the model integrates BI deployment, BI usage, individual impact, and organizational performance. This conceptualization helps to refocus the topic of BI maturity to business needs and can be used as a theoretical foundation for future research.},
	urldate = {2024-10-30},
	booktitle = {2011 44th {Hawaii} {International} {Conference} on {System} {Sciences}},
	publisher = {IEEE},
	author = {Lahrmann, G and Marx, F and Winter, R and Wortmann, F},
	month = jan,
	year = {2011},
	pages = {1--10},
}

@book{rokah_data_2015,
	address = {New Jersey London Singapore Beijing},
	edition = {2nd edition},
	series = {Series in machine perception and artificial intelligence},
	title = {Data mining with decision trees: theory and applications},
	isbn = {978-981-4590-07-5},
	shorttitle = {Data mining with decision trees},
	language = {eng},
	number = {volume 81},
	publisher = {World Scientific},
	author = {Roḳaḥ, Liʾor and Maimon, Oded Z.},
	year = {2015},
	keywords = {Data mining, Decision support systems, Decision trees, Machine learning},
}

@article{berners-lee_semantic_2001,
	edition = {Scientific American Magazine},
	title = {The {Semantic} {Web}: {A} new form of {Web} content that is meaningful to computers will unleash a revolution of new possibilities},
	shorttitle = {The {Semantic} {Web}},
	language = {en},
	journal = {Linking the World’s Information: Essays on Tim Berners-Lee’s Invention of the World Wide Web},
	author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
	month = may,
	year = {2001},
	keywords = {M2 - Thèse},
	pages = {91--103},
}

@incollection{guarino_ontologies_1995,
	title = {Ontologies and {Knowledge} {Bases}},
	isbn = {978-90-5199-217-5},
	abstract = {The word “ontology” has recently gained a good popularity within the knowledge engineering community. However, its meaning tends to remain a bit vague, as the term is used in very diﬀerent ways. Limiting our attention to the various proposals made in the current debate in AI, we isolate a number of interpretations, which in our opinion deserve a suitable clariﬁcation. We elucidate the implications of such various interpretations, arguing for the need of clear terminological choices regarding the technical use of terms like “ontology”, “conceptualization” and “ontological commitment”. After some comments on the use “Ontology” (with the capital “o”) as a term which denotes a philosophical discipline, we analyse the possible confusion between an ontology intended as a particular conceptual framework at the knowledge level and an ontology intended as a concrete artifact at the symbol level, to be used for a given purpose. A crucial point in this clariﬁcation eﬀort is the careful analysis of Gruber’ s deﬁnition of an ontology as a speciﬁcation of a conceptualization.},
	language = {en},
	booktitle = {Towards {Very} {Large} {Knowledge} {Bases}},
	publisher = {Mars, N.J.I.},
	author = {Guarino, Nicola and Giaretta, Pierdaniele},
	month = jan,
	year = {1995},
	pages = {25--32},
}

@article{cottafava_megaprojects_2024,
	title = {Megaprojects from the lens of business and management studies: {A} systematic literature review},
	volume = {24},
	copyright = {© 2024 John Wiley \& Sons Ltd.},
	issn = {1472-3891, 1479-1854},
	shorttitle = {Megaprojects from the lens of business and management studies},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/pa.2937},
	doi = {10.1002/pa.2937},
	abstract = {Megaprojects serve as the foundation of societal progress, providing essential infrastructure for a country's development and meeting its societal needs. There is a growing interest within the academic community to untangle the complex nature of megaprojects. This study conducts a comprehensive systematic literature review on megaprojects from the perspective of business, management, and accounting studies to provide a general map of the research conducted in this field and to highlight gaps for future research. The findings reveal thematic areas, including (i) sustainable development and decision‐making, (ii) governance approach, (iii) project management, (iv) risk assessment, and (v) economic and social effects/social responsibility. Moreover, identified gaps encompass limited consideration of the use/operation and end‐of‐life phases, inadequate evaluation of environmental and social impacts in economic terms, insufficient focus on sustainability reporting, inclusive governance, and using novel methodologies for complex system analysis in the field of megaprojects.},
	language = {en},
	number = {3},
	urldate = {2024-10-30},
	journal = {Journal of Public Affairs},
	author = {Cottafava, Dario and Corazza, Laura and Shams Esfandabadi, Zahra and Torchia, Daniel},
	month = aug,
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pa.2937},
	keywords = {Biblioshiny, bibliometric analysis, management studies, mega project, project management, socio-economic impacts},
	pages = {e2937},
}

@article{gulati_metaorganization_2012,
	title = {Meta‐organization design: {Rethinking} design in interorganizational and community contexts},
	volume = {33},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0143-2095, 1097-0266},
	shorttitle = {Meta‐organization design},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/smj.1975},
	doi = {10.1002/smj.1975},
	abstract = {Abstract
            This article provides conceptual foundations for analyzing organizations comprising multiple legally autonomous entities, which we call meta‐organizations. We assess the antecedents of the emergence of such collectives and the design choices they entail. The article identifies key parameters on which such meta‐organizations' designs differ from each other. It also presents a taxonomy that elucidates how such forms of collective action vary and the constraints they must address to be successful. We conclude with implications for research on meta‐organizational design. Copyright © 2012 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {6},
	urldate = {2024-10-30},
	journal = {Strategic Management Journal},
	author = {Gulati, Ranjay and Puranam, Phanish and Tushman, Michael},
	month = jun,
	year = {2012},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {communities, design, interorganizational relationships, meta, organization},
	pages = {571--586},
}

@article{mhiri_methodologie_2009,
	title = {Méthodologie de construction des ontologies pour la résolution de conflits des systèmes d'information},
	volume = {28},
	issn = {07524072},
	url = {http://tsi.revuesonline.com/article.jsp?articleId=14168},
	doi = {10.3166/tsi.28.1263-1287},
	abstract = {La modélisation d'un système d'information (SI) nécessite une parfaite connaissance du domaine concerné et une étude approfondie des exigences, sans cesse croissantes, des besoins des utilisateurs. Cette tâche devient très difficile en raison de la complexité des applications actuelles utilisant notamment des nouvelles technologies (e-learning, e-commerce, data warehouse, …) et la masse énorme de concepts provenant de sources hétérogènes. Ces problèmes peuvent engendrer différents types de conflits (syntaxiques, sémantiques et structurels). Comme solution, nous proposons l'utilisation des ontologies comme un moyen d'assistance aux concepteurs durant leur tâche de modélisation pour un domaine donné. Dans cet article, nous proposons une méthodologie de construction des ontologies pour la résolution des conflits des systèmes d'information. ABSTRACT. The information system (IS) modelling requires a perfect knowledge of the concerned field and a good study of user's requirements. This task becomes very difficult because the complexity of the current applications in particular using new technologies (e-learning, E-trade, data warehouse…) and the enormous mass of concepts coming from heterogeneous sources. These problems can generate various types of conflicts (syntactic, semantic and structural), we propose the ontology using to assist the designers during their task of modelling for a given field. In this paper, we propose an ontology building methodology to resolve their IS conflicts. MOTS-CLÉS : conception de systèmes d'information, ontologie, relations sémantiques, relations conceptuelles, UMLOnto.},
	number = {10},
	urldate = {2024-10-30},
	journal = {Techniques et sciences informatiques},
	author = {Mhiri, Mohamed and Gargouri, Faïez},
	month = dec,
	year = {2009},
	keywords = {Information systems design, UMLOnto, conceptual relationships, ontology, semantic relationships},
	pages = {1263--1287},
}

@inproceedings{aussenac-gilles_construction_2013,
	address = {Lille},
	title = {Construction d'ontologies à partir de pages web structurées},
	url = {https://hal.science/hal-00854428v1},
	language = {fr},
	author = {Aussenac-Gilles, Nathalie and Kamel, Mouna and Buscaldi, Davide and Comparot, Catherine},
	month = jul,
	year = {2013},
}

@article{kritsonis_comparison_2004,
	title = {Comparison of {Change} {Theories}},
	volume = {8},
	url = {http://www.csupomona.edu/~jvgrizzell/best_practices/bctheory.html},
	abstract = {The purpose of this article is to summarize several change theories and assumptions about the nature of change. The author shows how successful change can be encouraged and facilitated for long-term success. The article compares the characteristics of Lewin's Three-Step Change Theory, Lippitt's Phases of Change Theory, Prochaska and DiClemente's Change Theory, Social Cognitive Theory, and the Theory of Reasoned Action and Planned Behavior to one another. Leading industry experts will need to continually review and provide new information relative to the change process and to our evolving society and culture. here are many change theories and some of the most widely recognized are briefly summarized in this article. The theories serve as a testimony to the fact that change is a real phenomenon. It can be observed and analyzed through various steps or phases. The theories have been conceptualized to answer the question, "How does successful change happen?" Lewin's Three-Step Change Theory Kurt Lewin (1951) introduced the three-step change model. This social scientist views behavior as a dynamic balance of forces working in opposing directions. Driving forces facilitate change because they push employees in the desired direction. Restraining forces hinder change because they push employees in the opposite direction. Therefore, these forces must be analyzed and Lewin's three-step model can help shift the balance in the direction of the planned change},
	language = {en},
	number = {1},
	journal = {INTERNATIONAL JOURNAL OF SCHOLARLY ACADEMIC IN℡LECTUAL DIVERSITY},
	author = {Kritsonis, Alicia},
	year = {2004},
}

@article{prochaska_applying_2013,
	title = {Applying the stages of change},
	volume = {19},
	issn = {1323-0921},
	url = {https://search.informit.org/doi/abs/10.3316/INFORMIT.254435778545597},
	doi = {10.3316/informit.254435778545597},
	abstract = {From a transtheoretical perspective, PROCHASKA, NORCROSS and DICLEMENTE summarise prescriptive and proscriptive guidelines for improving treatments based on five stages of change the client may progress through - precontemplation, contemplation, preparation, action, and maintenance. Change is not viewed as a linear progression through the stages; rather, most clients move through the stages of change in a spiral pattern. While people progress from contemplation to preparation to action to maintenance, most will relapse. Fortunately, most move back to the contemplation stage and into preparation and action. Eleven practice recommendations are advanced against the central need to assess the stage of a client's readiness for change and to tailor interventions accordingly. A small and finite set of change processes or strategies have been identified across hundreds of psychotherapy techniques and across diverse disorders. Eight change process are outlined in detail. In the transtheoretical model, change processes associated with particular therapeutic models are applied optimally at each stage of change accompanied by stage-matched 'relationships of choice'. Guidance is given on how to avoid mismatching stages and processes. Smoking is used as an illustrative problem behaviour.},
	number = {2},
	urldate = {2024-07-04},
	journal = {Psychotherapy in Australia},
	author = {Prochaska, James O. and Norcross, John C. and DiClemente, Carlo C.},
	month = feb,
	year = {2013},
	note = {Publisher: PsychOz Publications},
	pages = {10--15},
}

@article{peersman_when_2016,
	title = {When and how to develop an impact-oriented monitoring and evaluation system},
	issn = {2052-7209},
	url = {www.betterevaluation.org},
	language = {en},
	author = {Peersman, Greet and Rogers, Patricia and Guijt, Irene and Hearn, Simon and Pasanen, Tiina and Buffardi, Anne L.},
	year = {2016},
}

@article{peersman_when_2016-1,
	title = {When and how to develop an impact-oriented monitoring and evaluation system - - {Working} and discussion papers},
	url = {https://policycommons.net/artifacts/4398154/when-and-how-to-develop-an-impact-oriented-monitoring-and-evaluation-system/5194773/},
	abstract = {When And hoW to deveLop An iMpAct-oriented Monitoring And evALuAtion systeM 9 table 4: holistic approach to M\&amp;e using the betterevaluation Framework Task What it entails Manage The planning and management of the implementation of the M\&amp;E system, including who will make decisions about it, who will lead development and implementation and the roles and responsibilitie. [...] Engagement from all stakeholders in In addition to gathering data for judging impact at the design and implementation of the M\&amp;E system can the end of the intervention period, inclusion of impact help buy-in and encourage the use of data for decision indicators in ongoing M\&amp;E efforts can provide useful making and learning. [...] Process monitoring and evaluation that the type of data to be collected, the way in which document what activities took place, with whom, where they are obtained and analysed, and the strategies and and how can help to rule out ‘implementation failure’ channels by which to present and share the findings as a possible explanation for the lack of intended longer with intended users. [...] The advantage of building measured), including the quality and quantity of this type of data collection/collation and analysis into input and activities, outputs, short-term and longer- ongoing M\&amp;E activities is: term outcomes and impacts • which longer term results will be able to be observed ‘It enables actors to critically and collaboratively during the life span of the intervention, and which. [...] Primarily, these are that: it helps to shift the focus of the assessment from indicators to impact-related questions, thereby broadening what can be learned about the value and worth of the intervention; it can improve the availability, timeliness and quality of data which are pertinent for decision making about the intervention; and it allows for early attention to collective sense-making and app.},
	language = {en},
	urldate = {2024-07-03},
	author = {Peersman, Greet and Rogers, Patricia and Guijt, Irene and Hearn, Simon and Buffardi, Tiina Pasanen {and} Anne L.},
	month = mar,
	year = {2016},
	note = {Publisher: {\textless}bound method Organization.get\_name\_with\_acronym of {\textless}Organization: Overseas Development Institute{\textgreater}{\textgreater}},
}

@misc{noauthor_transforming_nodate,
	title = {Transforming our world: the 2030 {Agenda} for {Sustainable} {Development} {\textbar} {Department} of {Economic} and {Social} {Affairs}},
	url = {https://sdgs.un.org/2030agenda},
	urldate = {2024-08-09},
}

@misc{noauthor_research_2019,
	title = {Research for {CULT} {Committee} - {The} {European} {Universities} {Initiative}: first lessons, main challenges and perspectives. {\textbar} {Think} {Tank} {\textbar} {European} {Parliament}},
	shorttitle = {Research for {CULT} {Committee} - {The} {European} {Universities} {Initiative}},
	url = {https://www.europarl.europa.eu/thinktank/en/document/IPOL_STU(2023)733105},
	abstract = {Research for CULT Committee - The European Universities Initiative: first lessons, main challenges and perspectives.},
	language = {en},
	urldate = {2024-07-03},
	year = {2019},
}

@misc{noauthor_rainbow_nodate,
	title = {Rainbow {Framework} - {Rainbow} {Framework}},
	url = {https://www.betterevaluation.org/frameworks-guides/rainbow-framework},
	abstract = {The Rainbow Framework organises these methods and processes in terms of the tasks that are often undertaken in M\&E.},
	language = {en},
	urldate = {2024-07-03},
}

@article{corazza_developing_2024,
	title = {Developing a societal impact evaluation framework for sustainable {European} {University} {Alliances}},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-63933-9},
	doi = {10.1038/s41598-024-63933-9},
	abstract = {European University alliances, formally introduced in 2019, are rapidly expanding, as more than 400 million euros have been dedicated in 2023 by the European Commission to foster international collaborations to promote new forms of development within and beyond university communities. By undertaking interventionist research on UNITA – Universitas Montium, one of the largest European alliances, representing 160.000 students, this paper aims to illustrate how a university alliance is tasked with developing an internal assessment methodology to account for the societal benefits created by the project for the academic and civil communities. The elaboration of the assessment tool to assess the contribution to higher education and societal sustainable communities has brought researchers to discover etic and emic implications, revealing the existence of an accountability layer in which the international alliance directly engages with rural and mountain communities in marginalized areas. This research marks a significant advancement in the field of higher education sustainability, providing both a novel analytical perspective on the benefits of university alliances for the development of local sustainable communities and a methodological tool for their assessment.},
	number = {1},
	journal = {Scientific Reports 2024 14:1},
	author = {Corazza, Laura and Marengo, Francesco and Torchia, Daniel and Sargiacomo, Massimo},
	month = jun,
	year = {2024},
	pmid = {38844814},
	note = {ISBN: 0123456789
Publisher: Nature Publishing Group},
	keywords = {Socioeconomic scenarios, Sustainability},
	pages = {1--12},
}

@article{di_tria_cost-benefit_2017,
	title = {Cost-benefit analysis of data warehouse design methodologies},
	volume = {63},
	issn = {0306-4379},
	url = {https://www.sciencedirect.com/science/article/pii/S0306437916302800},
	doi = {10.1016/j.is.2016.06.006},
	abstract = {Methodologies for data warehouse design are increasing more and more in last years, and each of them proposes a different point of view. Among all the methodologies present in literature, the promising ones are the hybrid methodologies—because they represent the only way to ensure a multidimensional schema to be both consistent with data sources and adherent to user business goals—and those able to support the designer by providing some kind of automation. However, the results obtainable by the methodologies can differ substantially in terms of schema quality and required efforts. In this paper, we provide metrics for evaluating the quality of multidimensional schemata in reference to the effort spent in the design process and the automation degree of the methodology. As a case study, we apply our evaluation to the major emerging hybrid methodologies for data warehouse schema design.},
	urldate = {2024-07-10},
	journal = {Information Systems},
	author = {Di Tria, Francesco and Lefons, Ezio and Tangorra, Filippo},
	month = jan,
	year = {2017},
	keywords = {Automation, Design effort, Evaluation, Metrics, Schema quality},
	pages = {47--62},
}

@article{jarke_architecture_1999,
	series = {10th {International} {Conference} on {Advanced} {Information} {Systems} {Engineering}},
	title = {Architecture and quality in data warehouses: {An} extended repository approach},
	volume = {24},
	issn = {0306-4379},
	shorttitle = {Architecture and quality in data warehouses},
	url = {https://www.sciencedirect.com/science/article/pii/S0306437999000174},
	doi = {10.1016/S0306-4379(99)00017-4},
	abstract = {Most database researchers have studied data warehouses (DW) in their role as buffers of materialized views, mediating between update-intensive OLTP systems and query-intensive decision support. This neglects the organizational role of data warehousing as a means of centralized information flow control. As a consequence, a large number of quality aspects relevant for data warehousing cannot be expressed with the current DW meta models. This paper makes two contributions towards solving these problems. Firstly, we enrich the meta data about DW architectures by explicit enterprise models. Secondly, many very different mathematical techniques for measuring or optimizing certain aspects of DW quality are being developed. We adapt the Goal-Question-Metric approach from software quality management to a meta data management environment in order to link these special techniques to a generic conceptual framework of DW quality. The approach has been implemented in full on top of the ConceptBase repository system and has undergone some validation by applying it to the support of specific quality-oriented methods, tools, and application projects in data warehousing.},
	number = {3},
	urldate = {2024-07-10},
	journal = {Information Systems},
	author = {Jarke, Matthias and Jeusfeld, Manfred A. and Quix, Christoph and Vassiliadis, Panos},
	month = may,
	year = {1999},
	keywords = {Conceptual Models, Data Quality, Data Warehouses, Meta Data Management, Repository},
	pages = {229--253},
}

@article{asirvadem_idef1x_nodate,
	title = {{IDEF1X} {Introduction}},
	language = {en},
	author = {Asirvadem, Derek},
}

@misc{noauthor_ranking_2024,
	title = {{THE} {Ranking} - {University} of {Pau} and {Pays} de l’{Adour}},
	url = {https://www.timeshighereducation.com/world-university-rankings/university-pau-and-pays-de-ladour},
	abstract = {The University of Pau and Pays de L’Adour was founded in 1970 but its history dates back to 1549 when the Collège des Arts, an institute for the humanities, was established. Today the university is the third largest of its kind in southwestern France, after Bordeaux and Toulouse. The university is based in Pau, a city in southwestern France. Pau is an old royal city set between the Pyrenees Mountains and the Atlantic Ocean. With more than 1,900 acres of green space, Pau is one of the greenest cities in Europe. It is also home to a number of museums including the National Museum of the Castle of Pau and the Pau Museum of Fine Arts. As well as the main Pau Campus, there are four other campuses: Anglet, Bayonne, Mont-de-Marsan, and Tarbes. Each campus is fully equipped with a library, sports facilities and a range of student associations. The university is organised into three colleges: the college of sciences and technology for energy and environment, the college of social science and the humanities, and the college of European and international studies. Each college consists of two levels: undergraduate studies and graduate studies, research and innovation. There are 24 research units at the university that carry out research in the following areas: environment and material, geo-resources, aquatic environments and resources, justice and territories, and areas, borders and blending.},
	language = {en},
	urldate = {2024-07-27},
	journal = {Times Higher Education (THE)},
	month = feb,
	year = {2024},
}

@misc{noauthor_17_nodate,
	title = {{THE} 17 {GOALS} {\textbar} {Sustainable} {Development}},
	url = {https://sdgs.un.org/goals},
	urldate = {2024-07-26},
}

@misc{noauthor_definition--ontology_nodate,
	title = {definition-of-ontology},
	url = {https://tomgruber.org/writing/definition-of-ontology.pdf},
	urldate = {2024-09-02},
}

@article{rudin_stop_nodate,
	title = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
	volume = {1},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-019-0048-x},
	doi = {10.1038/s42256-019-0048-x},
	abstract = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
	number = {5},
	author = {Rudin, Cynthia},
	keywords = {Computer science, Criminology, Science, Statistics, technology and society},
	pages = {206--215},
}

@book{oecd_quality_2010,
	address = {Paris},
	title = {Quality {Standards} for {Development} {Evaluation}},
	url = {https://www.oecd-ilibrary.org/development/dac-quality-standards-for-development-evaluation_9789264083905-en},
	abstract = {This reference guide lays out standards for each phase of a typical evaluation process: from defining purpose, to planning, designing, implementing, reporting, and learning from and using evaluation results.},
	language = {fr},
	urldate = {2024-07-06},
	publisher = {Organisation for Economic Co-operation and Development},
	author = {{OECD}},
	year = {2010},
}

@article{aussenac-gilles_open_2013,
	title = {Open {Archive} {TOULOUSE} {Archive} {Ouverte} ({OATAO}) {Construction} d'ontologie à partir d'une collection de pages web structurées},
	url = {http://www.igluski.com/france/},
	abstract = {OATAO is an open access repository that collects the work of Toulouse researchers and makes it freely available over the web where possible. This is an author-deposited version published in : http://oatao.univ-toulouse.fr/ Eprints ID : 12472 To cite this version : Aussenac-Gilles, Nathalie and Kamel, Mouna and Buscaldi, Davide and Comparot, Catherine Construction d'ontologies à partir de pages web structurées. Résumé : De nombreuses collections de documents disponibles sur le web dé-crivent les caractéristiques d'entités d'un même type (e.g. des produits, des plantes), chaque page présentant une de ces entités. Ces documents sont des sources de connaissances particulièrement adaptées pour la construction d'ontologies. Alors qu'ils partagent une même mise en forme régulière, ils contiennent moins de texte rédigé que des fichiers textes mais leur architecture est riche de sens. De ce fait, les méthodes linguistiques classiques pour identifier des concepts et des relations sont moins adaptées pour les analyser. Nous proposons une approche exploitant les di-verses propriétés de ces documents, combinant analyse de la structure et de la mise en forme avec une analyse linguistique, et exploitant leur annotation sémantique.},
	author = {Aussenac-Gilles, Nathalie and Kamel, Mouna and Buscaldi, Davide and Comparot, Catherine},
	year = {2013},
	keywords = {Annotation sémantique, Enrichissement d'ontologies, Mise en forme de documents, Mots-clés : Construction d'ontologies, Structure do-cumentaire},
}

@article{nemati_knowledge_2002,
	series = {Decision {Support} {System}: {Directions} for the {Nest} {Decade}},
	title = {Knowledge warehouse: an architectural integration of knowledge management, decision support, artificial intelligence and data warehousing},
	volume = {33},
	issn = {0167-9236},
	shorttitle = {Knowledge warehouse},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923601001415},
	doi = {10.1016/S0167-9236(01)00141-5},
	abstract = {Decision support systems (DSS) are becoming increasingly more critical to the daily operation of organizations. Data warehousing, an integral part of this, provides an infrastructure that enables businesses to extract, cleanse, and store vast amounts of data. The basic purpose of a data warehouse is to empower the knowledge workers with information that allows them to make decisions based on a solid foundation of fact. However, only a fraction of the needed information exists on computers; the vast majority of a firm's intellectual assets exist as knowledge in the minds of its employees. What is needed is a new generation of knowledge-enabled systems that provides the infrastructure needed to capture, cleanse, store, organize, leverage, and disseminate not only data and information but also the knowledge of the firm. The purpose of this paper is to propose, as an extension to the data warehouse model, a knowledge warehouse (KW) architecture that will not only facilitate the capturing and coding of knowledge but also enhance the retrieval and sharing of knowledge across the organization. The knowledge warehouse proposed here suggests a different direction for DSS in the next decade. This new direction is based on an expanded purpose of DSS. That is, the purpose of DSS in knowledge improvement. This expanded purpose of DSS also suggests that the effectiveness of a DSS will, in the future, be measured based on how well it promotes and enhances knowledge, how well it improves the mental model(s) and understanding of the decision maker(s) and thereby how well it improves his/her decision making.},
	number = {2},
	urldate = {2024-07-04},
	journal = {Decision Support Systems},
	author = {Nemati, Hamid R. and Steiger, David M. and Iyer, Lakshmi S. and Herschel, Richard T.},
	month = jun,
	year = {2002},
	pages = {143--161},
}

@book{youth_final_2023,
	title = {Final report of the study on the state and effectiveness of national funding systems of higher education to support the {European} universities initiative. {Volume} {I}.},
	url = {https://data.europa.eu/doi/10.2766/885757},
	publisher = {Publications Office},
	author = {Youth, Sport European Commission Directorate General for Education and {Culture.}},
	year = {2023},
}

@article{hanisch_digital_2023,
	title = {Digital governance: {A} conceptual framework and research agenda},
	volume = {162},
	issn = {0148-2963},
	shorttitle = {Digital governance},
	doi = {10.1016/j.jbusres.2023.113777},
	abstract = {The rapid expansion of digital technologies has paved the way for new forms of organizing, facilitated by increased data and knowledge exchange between individuals and organizations. However, this poses major new challenges for designing effective governance mechanisms. This paper highlights the critical role of digital governance in facilitating digitally enabled exchange relationships. To this end, we propose a typology of analog, augmented, and automated governance modes, each associated with specific control, coordination, incentive, and trust mechanisms. Additionally, we provide a heuristic for determining the optimal governance choice via the interplay of transactivity (i.e., the contributors, connections, and consistency in an exchange network) and corresponding governance costs. Our study advances the governance literature by defining digital governance as a distinct form and outlining key governance mechanisms and choices in the digital era. Finally, we identify avenues for future research in this field. © 2023 The Author(s)},
	language = {English},
	journal = {Journal of Business Research},
	author = {Hanisch, M. and Goldsby, C.M. and Fabian, N.E. and Oehmichen, J.},
	year = {2023},
	keywords = {Algorithmic management, Artificial intelligence, Blockchain, Corporate governance, Digital governance, Digital transformation, Interorganizational governance},
}

@article{bilal_application_2016,
	title = {Application of {Data} {Warehouse} in {Real} {Life}: {State}-of-the-art {Survey} from {User} {Preferences}’ {Perspective}},
	volume = {7},
	issn = {21565570, 2158107X},
	shorttitle = {Application of {Data} {Warehouse} in {Real} {Life}},
	url = {http://thesai.org/Publications/ViewPaper?Volume=7&Issue=4&Code=ijacsa&SerialNo=55},
	doi = {10.14569/IJACSA.2016.070455},
	abstract = {In recent years, due to increase in data complexity and manageability issues, data warehousing has attracted a great deal of interest in real life applications especially in business, finance, healthcare and industries. As the importance of retrieving the information from knowledge-base cannot be denied, data warehousing is all about making the information available for decision making. Data warehouse is accepted as the heart of the latest decision support systems. Due to the eagerness of data warehouse in real life, the need for the design and implementation of data warehouse in different applications is becoming crucial. Information from operational data sources are integrated by data warehousing into a central repository to start the process of analysis and mining of integrated information and primarily used in strategic decision making by means of online analytical processing techniques (OLAP). Despite the applications of data warehousing techniques in number of areas, there is no comprehensive literature review for it. This survey paper is an effort to present the applications of data warehouse in real life. It focuses to help the scholars knowing the analysis of data warehouse applications in number of domains. This survey provides applications, case studies and analysis of data warehouse used in various domains based on user preferences.},
	language = {en},
	number = {4},
	urldate = {2024-07-04},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Bilal, Muhammad and Sheikh, Umber and Raza, Basit and Javaid, Qaisar},
	year = {2016},
}

@misc{noauthor_utilizing_nodate,
	title = {Utilizing {Semantic} {Web} {Technologies} for {Efficient} {Data} {Lineage} and {Impact} {Analyses} in {Data} {Warehouse} {Environments} {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/5337540},
	urldate = {2024-07-04},
}

@misc{hearn_what_2016,
	title = {What is impact?},
	url = {https://odi.org/en/publications/what-is-impact/},
	abstract = {How \&\#039;impact\&\#039; is defined and used has a significant effect on the design, management and evaluation of development programmes.},
	language = {en-gb},
	urldate = {2024-07-03},
	journal = {ODI: Think change},
	author = {Hearn, Simon and Buffardi, Anne},
	month = feb,
	year = {2016},
}

@misc{noauthor_impact_2024,
	title = {Impact {Rankings}: {Affordable} and clean energy},
	shorttitle = {Impact {Rankings}},
	url = {https://www.timeshighereducation.com/impactrankings/affordable-and-clean-energy},
	abstract = {University Impact Rankings for UN SDG 7: Affordable and Clean Energy Times Higher Education has assessed and ranked 987 universities from 96 countries/regions for their exceptional efforts towards the United Nations’ Sustainable Development Goal 7: affordable and clean energy. These institutions stand out for their commitment to developing and promoting sustainable energy services, enhancing energy efficiency and fostering investments in energy infrastructure.},
	language = {en},
	urldate = {2024-07-27},
	journal = {Times Higher Education (THE)},
	month = jun,
	year = {2024},
}
